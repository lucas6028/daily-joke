# robots.txt

# This file is to prevent the crawling and indexing of certain parts
# of your site by web crawlers and bots.
# It is not a security mechanism; it's a hint for well-behaved bots.

# --- General access restrictions ---

# Disallow crawling of all content for all robots (very restrictive)
# User-agent: *
# Disallow: /

# Allow all robots to access everything (very permissive - use with caution)
# User-agent: *
# Allow: /

# --- Common bot-specific rules (recommended) ---

User-Agent: *
Allow: /
Disallow: /private/

# Googlebot (Google's web crawler)
User-agent: Googlebot
Disallow: /admin/  # Example: Disallow access to admin area
Disallow: /tmp/    # Example: Disallow access to temporary directories
Allow: /images/   # Example: Allow access to images directory (if needed)
Allow: /css/      # Example: Allow access to CSS directory (if needed)
Allow: /js/       # Example: Allow access to JavaScript directory (if needed)

# Googlebot-Image (Google's image crawler)
User-agent: Googlebot-Image
Allow: /images/

# Bingbot (Microsoft's web crawler)
User-agent: Bingbot
Disallow: /admin/
Disallow: /tmp/
Allow: /images/
Allow: /css/
Allow: /js/

# DuckDuckBot
User-agent: DuckDuckBot
Disallow: /admin/
Disallow: /tmp/
Allow: /images/
Allow: /css/
Allow: /js/

# Baiduspider (Baidu's web crawler - often ignores robots.txt)
User-agent: Baiduspider
Disallow: /

# OpenAI
User-agent: OAI-SearchBot
Disallow: /admin/
Disallow: /tmp/
Allow: /images/
Allow: /css/
Allow: /js/

User-agent: ChatGPT-User
Disallow: /admin/
Disallow: /tmp/
Allow: /images/
Allow: /css/
Allow: /js/

User-agent: GPTBot
Disallow: /admin/
Disallow: /tmp/
Allow: /images/
Allow: /css/
Allow: /js/


# --- Sitemap ---
# (Optional) Link to your sitemap file for easier crawling.
Sitemap: https://acme.com/sitemap.xml

# --- End of robots.txt ---
